{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "cUtGUOA2-_T0",
        "outputId": "853b0199-db4a-4434-b7d7-8c085bd8e8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"quotaExceeded\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HttpError",
          "evalue": "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?part=snippet&channelId=UCRUaaiMWGtE0jQxjucI82kg&publishedAfter=2024-12-08T20%3A37%3A44.016047Z&type=video&order=date&maxResults=50&key=AIzaSyC1lW3ypBKxVdsazjR3duQkBYQ2qB6YlR8&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-45c704abfdd6>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-45c704abfdd6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m  \u001b[0;31m# Current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mvideos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_new_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcreate_word_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-45c704abfdd6>\u001b[0m in \u001b[0;36mfetch_new_videos\u001b[0;34m(api_key, channel_id)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmaxResults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mvideos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?part=snippet&channelId=UCRUaaiMWGtE0jQxjucI82kg&publishedAfter=2024-12-08T20%3A37%3A44.016047Z&type=video&order=date&maxResults=50&key=AIzaSyC1lW3ypBKxVdsazjR3duQkBYQ2qB6YlR8&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from googleapiclient.discovery import build\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "import requests\n",
        "\n",
        "# Function to fetch new videos from a YouTube channel\n",
        "def fetch_new_videos(api_key, channel_id):\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "    # Calculate the date one week ago\n",
        "    one_week_ago = (datetime.utcnow() - timedelta(days=7)).isoformat(\"T\") + \"Z\"\n",
        "\n",
        "    # Fetch videos from the channel\n",
        "    request = youtube.search().list(\n",
        "        part=\"snippet\",\n",
        "        channelId=channel_id,\n",
        "        publishedAfter=one_week_ago,\n",
        "        type=\"video\",\n",
        "        order=\"date\",\n",
        "        maxResults=50\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    videos = []\n",
        "    for item in response.get('items', []):\n",
        "        video = {\n",
        "            'title': item['snippet']['title'],\n",
        "            'thumbnail': item['snippet']['thumbnails']['high']['url'],\n",
        "            'link': f\"https://www.youtube.com/watch?v={item['id']['videoId']}\"\n",
        "        }\n",
        "        videos.append(video)\n",
        "\n",
        "    return videos\n",
        "\n",
        "# Function to create a Word document with video details\n",
        "def create_word_doc(videos, output_path):\n",
        "    document = Document()\n",
        "    document.add_heading('YouTube Videos from the Past Week', level=1)\n",
        "\n",
        "    for video in videos:\n",
        "        document.add_heading(video['title'], level=2)\n",
        "        document.add_paragraph(video['link'])\n",
        "\n",
        "        # Fetch and insert the thumbnail\n",
        "        response = requests.get(video['thumbnail'])\n",
        "        if response.status_code == 200:\n",
        "            thumbnail_path = os.path.join(output_path, \"temp_thumbnail.jpg\")\n",
        "            with open(thumbnail_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            document.add_picture(thumbnail_path, width=Inches(2))\n",
        "            os.remove(thumbnail_path)\n",
        "\n",
        "    # Save the Word document\n",
        "    doc_path = os.path.join(output_path, 'YouTube_Videos_This_Week.docx')\n",
        "    document.save(doc_path)\n",
        "    print(f\"Document saved at: {doc_path}\")\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    api_key = 'AIzaSyC1lW3ypBKxVdsazjR3duQkBYQ2qB6YlR8'  # Your YouTube API Key\n",
        "    channel_id = 'UCRUaaiMWGtE0jQxjucI82kg'  # Your Channel ID\n",
        "    output_path = '.'  # Current directory\n",
        "\n",
        "    videos = fetch_new_videos(api_key, channel_id)\n",
        "    if videos:\n",
        "        create_word_doc(videos, output_path)\n",
        "    else:\n",
        "        print(\"No new videos found for the past week.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4 python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_90E5supA93P",
        "outputId": "a3d8ae80-62ad-49bd-df44-92dd26fa81e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from docx import Document\n",
        "from docx.shared import Inches, Pt\n",
        "import time\n",
        "\n",
        "# Function to fetch new videos from a YouTube channel without using the API\n",
        "def fetch_new_videos_scrape(channel_id):\n",
        "    start_time = time.time()\n",
        "    url = f\"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(\"Failed to fetch video feed.\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'xml')\n",
        "    videos = []\n",
        "    one_week_ago = (datetime.utcnow() - timedelta(days=7)).replace(tzinfo=timezone.utc)  # Make timezone-aware\n",
        "\n",
        "    channel_title = soup.find('title').text\n",
        "    channel_logo_url = soup.find('logo').text if soup.find('logo') else None\n",
        "\n",
        "    for entry in soup.find_all('entry'):\n",
        "        video_published = datetime.strptime(entry.published.text, \"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        if video_published > one_week_ago:\n",
        "            high_quality_thumbnail = entry.find('media:thumbnail')['url'].replace('hqdefault.jpg', 'maxresdefault.jpg')\n",
        "            video = {\n",
        "                'title': entry.title.text,\n",
        "                'link': entry.link['href'],\n",
        "                'thumbnail': high_quality_thumbnail,\n",
        "                'published': video_published.strftime('%Y-%m-%d %H:%M:%S UTC'),\n",
        "                'description': entry.find('media:description').text if entry.find('media:description') else \"No description available.\"\n",
        "            }\n",
        "            videos.append(video)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Scraping completed in {elapsed_time:.2f} seconds with {len(videos)} videos fetched.\")\n",
        "    return videos, elapsed_time, channel_title, channel_logo_url\n",
        "\n",
        "# Function to create a Word document with video details\n",
        "def create_word_doc(videos, elapsed_time, output_path, channel_id, channel_title, channel_logo_url):\n",
        "    document = Document()\n",
        "\n",
        "    # Add a sci-fi styled title\n",
        "    title = document.add_heading(level=1)\n",
        "    run = title.add_run('YouTube Weekly Video Report')\n",
        "    run.font.name = 'Orbitron'  # Sci-fi font (use a similar available font if Orbitron isn't installed)\n",
        "    run.font.size = Pt(24)\n",
        "\n",
        "    # Channel details\n",
        "    if channel_logo_url:\n",
        "        response = requests.get(channel_logo_url)\n",
        "        if response.status_code == 200:\n",
        "            logo_path = os.path.join(output_path, \"channel_logo.jpg\")\n",
        "            with open(logo_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            document.add_picture(logo_path, width=Inches(1.5))\n",
        "            os.remove(logo_path)\n",
        "\n",
        "    document.add_heading(channel_title, level=2)\n",
        "    document.add_paragraph(f\"Channel ID: {channel_id}\")\n",
        "    document.add_paragraph(f\"Report Generated On: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
        "    document.add_paragraph(f\"Time Taken to Fetch Videos: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "    # Add a separator\n",
        "    separator = document.add_paragraph()\n",
        "    separator_run = separator.add_run(\"=\" * 50)\n",
        "    separator_run.bold = True\n",
        "\n",
        "    for idx, video in enumerate(videos, 1):\n",
        "        document.add_heading(f\"{idx}. {video['title']}\", level=2)\n",
        "        document.add_paragraph(f\"Video Link: {video['link']}\")\n",
        "        document.add_paragraph(f\"Published On: {video['published']}\")\n",
        "        document.add_paragraph(f\"Description: {video['description']}\")\n",
        "\n",
        "        # Fetch and insert the high-quality thumbnail\n",
        "        response = requests.get(video['thumbnail'])\n",
        "        if response.status_code == 200:\n",
        "            thumbnail_path = os.path.join(output_path, f\"temp_thumbnail_{idx}.jpg\")\n",
        "            with open(thumbnail_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            document.add_picture(thumbnail_path, width=Inches(3))\n",
        "            os.remove(thumbnail_path)\n",
        "\n",
        "        # Add a separator between videos\n",
        "        separator = document.add_paragraph()\n",
        "        separator_run = separator.add_run(\"-\" * 50)\n",
        "        separator_run.bold = True\n",
        "\n",
        "    # Add logs at the end\n",
        "    document.add_page_break()\n",
        "    document.add_heading(\"Debug Insights\", level=1)\n",
        "    document.add_paragraph(f\"Total Videos Fetched: {len(videos)}\")\n",
        "    document.add_paragraph(f\"Time Taken: {elapsed_time:.2f} seconds\")\n",
        "    document.add_paragraph(f\"Channel: {channel_title}\")\n",
        "    document.add_paragraph(f\"Channel ID: {channel_id}\")\n",
        "\n",
        "    # Save the Word document\n",
        "    doc_path = os.path.join(output_path, 'YouTube_Videos_This_Week.docx')\n",
        "    document.save(doc_path)\n",
        "    print(f\"Document saved at: {doc_path}\")\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    channel_id = 'UCeoSGHaFePbHGtJjn0xUPrw'  # Your Channel ID\n",
        "    output_path = '.'  # Current directory\n",
        "\n",
        "    videos, elapsed_time, channel_title, channel_logo_url = fetch_new_videos_scrape(channel_id)\n",
        "    if videos:\n",
        "        create_word_doc(videos, elapsed_time, output_path, channel_id, channel_title, channel_logo_url)\n",
        "    else:\n",
        "        print(\"No new videos found for the past week.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuVYFUM4_xtJ",
        "outputId": "65694831-2571-4042-b2d1-3f3c701cc048"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping completed in 0.18 seconds with 1 videos fetched.\n",
            "Document saved at: ./YouTube_Videos_This_Week.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx"
      ],
      "metadata": {
        "id": "I4Ou1myRDCZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a37624c-3c17-440b-8a43-e030895f798f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (5.3.0)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (11.0.0)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53892 sha256=d472cb71a0e83ce5118fe1f5d0d7b87b55838ffbc5e518a2c9d5a0d628743960\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f5/1d/e09ba2c1907a43a4146d1189ae4733ca1a3bfe27ee39507767\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T2geqN8Ej4qG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}